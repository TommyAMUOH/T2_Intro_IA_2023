# -*- coding: utf-8 -*-
"""TAREA2_IA_CÓDIGO.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1myVJ9GP6rd7DDXfhCYkeTtCT5yXy51vD

# Universidad de O'Higgins

## Escuela de Ingeniería
## COM4402: Introducción a Inteligencia Artificial

### **Tarea 2: Clasificación de Dígitos Manuscritos con Redes Neuronales**

### Estudiante: Tomás Enrique Araya Miranda

El objetivo de esta tarea es utilizar redes neuronales en un problema de clasificación de dígitos. Se utilizará el conjunto de datos Optical Recognition of Handwritten Digits Data Set. Este conjunto tiene 64 características, con 10 clases y 5620 muestras en total. La base de datos estará disponible en U-Campus.

Las redes a ser entrenadas tienen la siguiente estructura: capa de entrada de dimensionalidad 64 (correspondiente a los datos de entrada), capas ocultas (una o dos) y capa de salida con 10 neuronas y función de activación softmax. La función de loss (pérdida) es entropía cruzada. El optimizador que se
debe usar es Adam. La función softmax está implícita al usar la función de pérdida CrossEntropyLoss de PyTorch (**no se debe agregar softmax a la salida de la red**).

Se usará PyTorch para entrenar y validar la red neuronal que implementa el clasificador de dígitos. Se analizará los efectos de cambiar el tamaño de la red (número de capas ocultas y de neuronas en estas
capas) y la función de activación.

El siguiente código base debe ser usado para realizar las actividades pedidas.

## Observación: Antes de ejecutar su código, active el uso de GPU en Google Colab para acelerar el proceso de entrenamiento.

### Para esto: vaya a "Entorno de Ejecución" en el menú superior, haga click en "Cambiar tipo de entorno de ejecución", y seleccionar/verificar "GPU" en "Acelerador de Hardware"
"""

import pandas as pd
import torch
import torch.nn as nn
import numpy as np
import time
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

"""## Subir datasets de dígitos (train)"""

from google.colab import drive                                                  # conectar con google drive
drive.mount('/content/drive')

!wget https://raw.githubusercontent.com/Felipe1401/Mineria/main/dataset_digits/1_digits_train.txt  # importo 1_digits_train.txt
!wget https://raw.githubusercontent.com/Felipe1401/Mineria/main/dataset_digits/1_digits_test.txt   # importo 1_digits_test.txt

"""## Leer dataset de dígitos"""

column_names = ["feat" + str(i) for i in range(64)]                             # Usa comprensión de lista para generar nombres. "feat0" a "feat63".
column_names.append("class")                                                    # agregar columna class

df_train_val = pd.read_csv('1_digits_train.txt', names = column_names)          # Leer datos (como dataframe de pandas)
df_train_val                                                                    # conjunto de entrenamiento

df_test = pd.read_csv('1_digits_test.txt', names = column_names)                # Leer datos (como dataframe de pandas)
df_test                                                                         # conjunto de prueba

df_train, df_val = train_test_split(df_train_val, test_size = 0.3, random_state = 10) # 1. Divide el DataFrame `df_train_val` en dos DataFrames, `df_train` y `df_val`.
                                                                                      # 2. La división se realiza en una proporción del 70% para `df_train` y 30% para `df_val`.
                                                                                      # 3. Se utiliza una semilla (`random_state`) de 10 para reproducibilidad.

# normalización de los datos
scaler = StandardScaler().fit(df_train.iloc[:,0:64])                            # Crea un objeto scaler que aplica la estandarización (z-score) a los datos. Ajusta el escalador utilizando las columnas 0 a 63 de df_train.
                                                                                # Los valores de estas columnas se reemplazarán por los valores escalados utilizando el objeto scaler previamente ajustado.
df_train.iloc[:,0:64] = scaler.transform(df_train.iloc[:,0:64])                 # Aplica la transformación de escala a las columnas 0 a 63 del DataFrame df_train.
df_val.iloc[:,0:64] = scaler.transform(df_val.iloc[:,0:64])                     # Aplica la misma transformación de escala utilizada en df_train a las columnas 0 a 63 del DataFrame df_val.
df_test.iloc[:,0:64] = scaler.transform(df_test.iloc[:,0:64])                   # Realiza la misma transformación de escala que se hizo en los conjuntos de entrenamiento y validación, pero ahora se aplica a las columnas 0 a 63 del DataFrame df_test

df_train

"""## Crear datasets y dataloaders para pytorch (train)"""

# Crear datasets
feats_train = df_train.to_numpy()[:,0:64].astype(np.float32)                                                         # Extrae características de DataFrame de entrenamiento.
labels_train = df_train.to_numpy()[:,64].astype(int)                                                                 # Extrae etiquetas del DataFrame de entrenamiento.
dataset_train = [ {"features":feats_train[i,:], "labels":labels_train[i]} for i in range(feats_train.shape[0]) ]     # Crea conjunto de datos de entrenamiento.

feats_val = df_val.to_numpy()[:,0:64].astype(np.float32)                                                             # Extrae características de DataFrame de validación.
labels_val = df_val.to_numpy()[:,64].astype(int)                                                                     # Extrae etiquetas del DataFrame de validación.
dataset_val = [ {"features":feats_val[i,:], "labels":labels_val[i]} for i in range(feats_val.shape[0]) ]             # Crea conjunto de datos de validación.

feats_test = df_test.to_numpy()[:,0:64].astype(np.float32)                                                           # Extrae características de DataFrame de prueba.
labels_test = df_test.to_numpy()[:,64].astype(int)                                                                   # Extrae etiquetas del DataFrame de prueba.
dataset_test = [ {"features":feats_test[i,:], "labels":labels_test[i]} for i in range(feats_test.shape[0]) ]         # Crea conjunto de datos de prueba.

# Crear dataloaders
dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=128, shuffle=True, num_workers=0)           # Crea DataLoader para entrenamiento con lotes de 128 ejemplos, mezclando y sin trabajadores.
dataloader_val = torch.utils.data.DataLoader(dataset_val, batch_size=128, shuffle=True, num_workers=0)               # Crea DataLoader para validación con lotes de 128 ejemplos, mezclando y sin trabajadores.
dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=128, shuffle=True, num_workers=0)             # Crea DataLoader para prueba con lotes de 128 ejemplos, mezclando y sin trabajadores.

"""## Escenario 2a"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from sklearn.metrics import accuracy_score
import numpy as np

# Crear modelo para el escenario 2.a
model_a = nn.Sequential(
    nn.Linear(64, 10), # Capa oculta con 10 neuronas y función de activación ReLU
    nn.ReLU(),
    nn.Linear(10, 10)  # Capa de salida con 10 neuronas (igual al número de clases)
)
#configuración dispositivo de entrenamiento
device = torch.device('cuda')
model_a = model_a.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model_a.parameters(), lr=1e-3)
start = time.time()
# Inicializar variables para el seguimiento
max_epochs = 1000
best_val_loss = float('inf')
wait = 0  # Contador para la parada anticipada

train_loss_list = []
val_loss_list = []
all_train_preds = []
all_train_labels = []

#entrenamiento de la red
for epoch in range(max_epochs):
    model_a.train()
    running_train_loss = 0.0
    all_preds = []
    all_labels = []

    for i, data in enumerate(dataloader_train, 0):
        inputs = data["features"].to(device)   # caraterísticas
        labels = data["labels"].to(device)     # clases
        optimizer.zero_grad()
        outputs = model_a(inputs)              # predicciones
        loss = criterion(outputs, labels)      # perdida de entrenamiento
        loss.backward()
        optimizer.step()
        running_train_loss += loss.item()
        all_preds.extend(outputs.argmax(dim=1).cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

    # Calcular el loss de entrenamiento promedio en esta época
    train_loss = running_train_loss / len(dataloader_train)
    train_loss_list.append(train_loss)

    #validación y seguimiento
    model_a.eval()
    running_val_loss = 0.0
    all_val_preds = []
    all_val_labels = []

    with torch.no_grad():
        for data in dataloader_val:
            inputs = data["features"].to(device)
            labels = data["labels"].to(device)
            outputs = model_a(inputs)
            loss = criterion(outputs, labels)   # perdida de validación
            running_val_loss += loss.item()
            all_val_preds.extend(outputs.argmax(dim=1).cpu().numpy())
            all_val_labels.extend(labels.cpu().numpy())

    # Calcular el loss de validación promedio en esta época
    val_loss = running_val_loss / len(dataloader_val)
    val_loss_list.append(val_loss)

    # Calcular el accuracy de validación
    val_accuracy = accuracy_score(all_val_labels, all_val_preds)

    # Calcular el accuracy de entrenamiento
    train_accuracy = accuracy_score(all_labels, all_preds)

    # Imprimir métricas de esta época
    print(f'Epoch {epoch} - Pérdida de entrenamiento: {train_loss:.4f} - Pérdida de validación: {val_loss:.4f} - Precisión del entrenamiento: {train_accuracy:.4f} - Precisión de la validación: {val_accuracy:.4f}')


    # Comprobar si el loss de validación está disminuyendo
    if val_loss < best_val_loss:
        best_val_loss = val_loss
        wait = 0
    else:
        wait += 1

    # Comprobar la condición de parada anticipada
    n_wait = 10
    if wait >= n_wait:
        print(f'Parada anticipada: No se ha observado mejora significativa en {n_wait} épocas.')
        print(f'Parada anticipada en la época {epoch}')
        break
end = time.time()
print('Finished Training, total time %f seconds' % (end - start))
# Imprimir los resultados finales
print(f'Precisión de entrenamiento al final del entrenamiento: {train_accuracy * 100:.2f}%')
print(f'Precisión de validación en la época {epoch}: {val_accuracy * 100:.2f}%')

import matplotlib.pyplot as plt
plt.figure(figsize=(12, 6))
plt.plot(train_loss_list, label='Training Loss', marker='o', markersize=5)
plt.plot(val_loss_list, label='Validation Loss', marker='o', markersize=5)
plt.grid(True)
plt.title('Escenario 2.a')
plt.xlabel('Epoch')
plt.ylabel('Pérdida')
plt.legend()
plt.show()

from sklearn.metrics import confusion_matrix
import seaborn as sns

# Calcular la matriz de confusión y el accuracy para el conjunto de validación
val_preds = np.array(all_val_preds)
val_labels = np.array(all_val_labels)
val_confusion = confusion_matrix(val_labels, val_preds, normalize='true')
val_accuracy_a = accuracy_score(val_labels, val_preds)

# Calcular la matriz de confusión y el accuracy para el conjunto de entrenamiento
train_preds = np.array(all_preds)
train_labels = np.array(all_labels)
train_confusion = confusion_matrix(train_labels, train_preds, normalize='true')
train_accuracy = accuracy_score(train_labels, train_preds)

# Crear una figura y ejes para la matriz de confusión
fig, axes = plt.subplots(1, 2, figsize=(15, 6))
fig.suptitle("Matrices de Confusión Normalizadas para escenario 2a", fontsize=16)

# Visualizar la matriz de confusión de validación
ax = axes[0]
sns.heatmap(val_confusion, annot=True, fmt='.2f', cmap='Blues', cbar=False, square=True, ax=ax, annot_kws={"size": 12})
ax.set_title("Validación")
ax.set_xlabel('Clase Predicha')
ax.set_ylabel('Clase Real')

# Visualizar la matriz de confusión de entrenamiento
ax = axes[1]
sns.heatmap(train_confusion, annot=True, fmt='.2f', cmap='Blues', cbar=False, square=True, ax=ax, annot_kws={"size": 12})
ax.set_title("Entrenamiento")
ax.set_xlabel('Clase Predicha')
ax.set_ylabel('Clase Real')

# Mostrar la figura
plt.show()

# Imprimir los resultados finales
print(f'Precisión de entrenamiento al final del entrenamiento: {train_accuracy * 100:.2f}%')
print(f'Precisión de validación en la época {epoch}: {val_accuracy_a * 100:.2f}%')

"""## Escenario 2b"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from sklearn.metrics import accuracy_score
import numpy as np

# Crear modelo para el escenario 2.b
model_b = nn.Sequential(
    nn.Linear(64, 40),  # Capa oculta con 40 neuronas y función de activación ReLU
    nn.ReLU(),
    nn.Linear(40, 10)  # Capa de salida con 10 neuronas (igual al número de clases)
)

device = torch.device('cuda')
model_b = model_b.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model_b.parameters(), lr=1e-3, weight_decay=1e-4)
start = time.time()
# Inicializar variables para el seguimiento
max_epochs = 1000  # Máxima cantidad de épocas
best_val_loss = float('inf')
wait = 0  # Contador para la parada anticipada

train_loss_list = []
val_loss_list = []
all_train_preds = []
all_train_labels = []

for epoch in range(max_epochs):
    model_b.train()
    running_train_loss = 0.0
    all_preds = []
    all_labels = []

    for i, data in enumerate(dataloader_train, 0):
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)
        optimizer.zero_grad()
        outputs = model_b(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_train_loss += loss.item()
        all_preds.extend(outputs.argmax(dim=1).cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

    # Calcular el loss de entrenamiento promedio en esta época
    train_loss = running_train_loss / len(dataloader_train)
    train_loss_list.append(train_loss)

    model_b.eval()
    running_val_loss = 0.0
    all_val_preds = []
    all_val_labels = []

    with torch.no_grad():
        for data in dataloader_val:
            inputs = data["features"].to(device)
            labels = data["labels"].to(device)
            outputs = model_b(inputs)
            loss = criterion(outputs, labels)
            running_val_loss += loss.item()
            all_val_preds.extend(outputs.argmax(dim=1).cpu().numpy())
            all_val_labels.extend(labels.cpu().numpy())

    # Calcular el loss de validación promedio en esta época
    val_loss = running_val_loss / len(dataloader_val)
    val_loss_list.append(val_loss)

    # Calcular el accuracy de validación
    val_accuracy = accuracy_score(all_val_labels, all_val_preds)

    # Calcular el accuracy de entrenamiento
    train_accuracy = accuracy_score(all_labels, all_preds)

    # Imprimir métricas de esta época
    print(f'Epoch {epoch} - Pérdida de entrenamiento: {train_loss:.4f} - Pérdida de validación: {val_loss:.4f} - Precisión del entrenamiento: {train_accuracy:.4f} - Precisión de la validación: {val_accuracy:.4f}')

    # Comprobar si el loss de validación está disminuyendo
    if val_loss < best_val_loss:
        best_val_loss = val_loss
        wait = 0
    else:
        wait += 1

    # Comprobar la condición de parada anticipada
    n_wait = 3
    if wait >= n_wait:
        print(f'Parada anticipada: No se ha observado mejora significativa en {n_wait} épocas.')
        print(f'Parada anticipada en la época {epoch}')
        break
end = time.time()
print('Finished Training, total time %f seconds' % (end - start))
# Imprimir los resultados finales
print(f'Precisión de entrenamiento al final del entrenamiento: {train_accuracy * 100:.2f}%')
print(f'Precisión de validación en la época {epoch}: {val_accuracy * 100:.2f}%')

import matplotlib.pyplot as plt

plt.figure(figsize=(12, 6))
plt.plot(train_loss_list, label='Training Loss', marker='o', markersize=5)
plt.plot(val_loss_list, label='Validation Loss', marker='o', markersize=5)
plt.grid(True)
plt.title('Escenario 2.b')
plt.xlabel('Epoch')
plt.ylabel('Pérdida')
plt.legend()
plt.show()

from sklearn.metrics import confusion_matrix
import seaborn as sns

# Calcular la matriz de confusión y el accuracy para el conjunto de validación
val_preds = np.array(all_val_preds)
val_labels = np.array(all_val_labels)
val_confusion = confusion_matrix(val_labels, val_preds, normalize='true')
val_accuracy_b = accuracy_score(val_labels, val_preds)

# Calcular la matriz de confusión y el accuracy para el conjunto de entrenamiento
train_preds = np.array(all_preds)
train_labels = np.array(all_labels)
train_confusion = confusion_matrix(train_labels, train_preds, normalize='true')
train_accuracy = accuracy_score(train_labels, train_preds)

# Crear una figura y ejes para la matriz de confusión
fig, axes = plt.subplots(1, 2, figsize=(15, 6))
fig.suptitle("Matrices de Confusión Normalizadas para escenario 2b", fontsize=16)

# Visualizar la matriz de confusión de validación
ax = axes[0]
sns.heatmap(val_confusion, annot=True, fmt='.2f', cmap='Blues', cbar=False, square=True, ax=ax, annot_kws={"size": 12})
ax.set_title("Validación")
ax.set_xlabel('Clase Predicha')
ax.set_ylabel('Clase Real')

# Visualizar la matriz de confusión de entrenamiento
ax = axes[1]
sns.heatmap(train_confusion, annot=True, fmt='.2f', cmap='Blues', cbar=False, square=True, ax=ax, annot_kws={"size": 12})
ax.set_title("Entrenamiento")
ax.set_xlabel('Clase Predicha')
ax.set_ylabel('Clase Real')

# Mostrar la figura
plt.show()

# Imprimir los resultados finales
print(f'Precisión de entrenamiento al final del entrenamiento: {train_accuracy * 100:.2f}%')
print(f'Precisión de validación en la época {epoch}: {val_accuracy_b * 100:.2f}%')

"""#Escenario 2c"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from sklearn.metrics import accuracy_score
import numpy as np

# Crear modelo para el escenario 2.c
model_c = nn.Sequential(
    nn.Linear(64, 10),  # Capa oculta con 10 neuronas
    nn.Tanh(),  # Función de activación Tanh
    nn.Linear(10, 10)  # Capa de salida con 10 neuronas (igual al número de clases)
)

device = torch.device('cuda')
model_c = model_c.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model_c.parameters(), lr=1e-3)
start = time.time()
# Inicializar variables para el seguimiento
max_epochs = 1000
best_val_loss = float('inf')
wait = 0  # Contador para la parada anticipada

train_loss_list = []
val_loss_list = []
all_train_preds = []
all_train_labels = []

for epoch in range(max_epochs):
    model_c.train()
    running_train_loss = 0.0
    all_preds = []
    all_labels = []

    for i, data in enumerate(dataloader_train, 0):
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)
        optimizer.zero_grad()
        outputs = model_c(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_train_loss += loss.item()
        all_preds.extend(outputs.argmax(dim=1).cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

    # Calcular el loss de entrenamiento promedio en esta época
    train_loss = running_train_loss / len(dataloader_train)
    train_loss_list.append(train_loss)

    model_c.eval()
    running_val_loss = 0.0
    all_val_preds = []
    all_val_labels = []

    with torch.no_grad():
        for data in dataloader_val:
            inputs = data["features"].to(device)
            labels = data["labels"].to(device)
            outputs = model_c(inputs)
            loss = criterion(outputs, labels)
            running_val_loss += loss.item()
            all_val_preds.extend(outputs.argmax(dim=1).cpu().numpy())
            all_val_labels.extend(labels.cpu().numpy())

    # Calcular el loss de validación promedio en esta época
    val_loss = running_val_loss / len(dataloader_val)
    val_loss_list.append(val_loss)

    # Calcular el accuracy de validación
    val_accuracy = accuracy_score(all_val_labels, all_val_preds)

    # Calcular el accuracy de entrenamiento
    train_accuracy = accuracy_score(all_labels, all_preds)

    # Imprimir métricas de esta época
    print(f'Epoch {epoch} - Pérdida de entrenamiento: {train_loss:.4f} - Pérdida de validación: {val_loss:.4f} - Precisión del entrenamiento: {train_accuracy:.4f} - Precisión de la validación: {val_accuracy:.4f}')


    # Comprobar si el loss de validación está disminuyendo
    if val_loss < best_val_loss:
        best_val_loss = val_loss
        wait = 0
    else:
        wait += 1

    # Comprobar la condición de parada anticipada
    n_wait = 8
    if wait >= n_wait:
        print(f'Parada anticipada: No se ha observado mejora significativa en {n_wait} épocas.')
        print(f'Parada anticipada en la época {epoch}')
        break
end = time.time()
print('Finished Training, total time %f seconds' % (end - start))
# Imprimir los resultados finales
print(f'Precisión de entrenamiento al final del entrenamiento: {train_accuracy * 100:.2f}%')
print(f'Precisión de validación en la época {epoch}: {val_accuracy * 100:.2f}%')

import matplotlib.pyplot as plt

plt.figure(figsize=(12, 6))
plt.plot(train_loss_list, label='Training Loss', marker='o', markersize=5)
plt.plot(val_loss_list, label='Validation Loss', marker='o', markersize=5)
plt.grid(True)
plt.title('Escenario 2.c')
plt.xlabel('Epoch')
plt.ylabel('Pérdida')
plt.legend()
plt.show()

from sklearn.metrics import confusion_matrix
import seaborn as sns

# Calcular la matriz de confusión y el accuracy para el conjunto de validación
val_preds = np.array(all_val_preds)
val_labels = np.array(all_val_labels)
val_confusion = confusion_matrix(val_labels, val_preds, normalize='true')
val_accuracy_c = accuracy_score(val_labels, val_preds)

# Calcular la matriz de confusión y el accuracy para el conjunto de entrenamiento
train_preds = np.array(all_preds)
train_labels = np.array(all_labels)
train_confusion = confusion_matrix(train_labels, train_preds, normalize='true')
train_accuracy = accuracy_score(train_labels, train_preds)

# Crear una figura y ejes para la matriz de confusión
fig, axes = plt.subplots(1, 2, figsize=(15, 6))
fig.suptitle("Matrices de Confusión Normalizadas para escenario 2c", fontsize=16)

# Visualizar la matriz de confusión de validación
ax = axes[0]
sns.heatmap(val_confusion, annot=True, fmt='.2f', cmap='Blues', cbar=False, square=True, ax=ax, annot_kws={"size": 12})
ax.set_title("Validación")
ax.set_xlabel('Clase Predicha')
ax.set_ylabel('Clase Real')

# Visualizar la matriz de confusión de entrenamiento
ax = axes[1]
sns.heatmap(train_confusion, annot=True, fmt='.2f', cmap='Blues', cbar=False, square=True, ax=ax, annot_kws={"size": 12})
ax.set_title("Entrenamiento")
ax.set_xlabel('Clase Predicha')
ax.set_ylabel('Clase Real')

# Mostrar la figura
plt.show()

# Imprimir los resultados finales
print(f'Precisión de entrenamiento al final del entrenamiento: {train_accuracy * 100:.2f}%')
print(f'Precisión de validación en la época {epoch}: {val_accuracy_c * 100:.2f}%')

"""## Escenario 2d"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from sklearn.metrics import accuracy_score
import numpy as np


# Crear modelo para el escenario 2.d
model_d = nn.Sequential(
    nn.Linear(64, 40),  # Capa oculta con 40 neuronas
    nn.Tanh(),  # Función de activación Tanh
    nn.Linear(40, 10)  # Capa de salida con 10 neuronas (igual al número de clases)
)

device = torch.device('cuda')
model_d = model_d.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model_d.parameters(), lr=1e-3)
start = time.time()
# Inicializar variables para el seguimiento
max_epochs = 1000
best_val_loss = float('inf')
wait = 0  # Contador para la parada anticipada

train_loss_list = []
val_loss_list = []
all_train_preds = []
all_train_labels = []

for epoch in range(max_epochs):
    model_d.train()
    running_train_loss = 0.0
    all_preds = []
    all_labels = []

    for i, data in enumerate(dataloader_train, 0):
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)
        optimizer.zero_grad()
        outputs = model_d(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_train_loss += loss.item()
        all_preds.extend(outputs.argmax(dim=1).cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

    # Calcular el loss de entrenamiento promedio en esta época
    train_loss = running_train_loss / len(dataloader_train)
    train_loss_list.append(train_loss)

    model_d.eval()
    running_val_loss = 0.0
    all_val_preds = []
    all_val_labels = []

    with torch.no_grad():
        for data in dataloader_val:
            inputs = data["features"].to(device)
            labels = data["labels"].to(device)
            outputs = model_d(inputs)
            loss = criterion(outputs, labels)
            running_val_loss += loss.item()
            all_val_preds.extend(outputs.argmax(dim=1).cpu().numpy())
            all_val_labels.extend(labels.cpu().numpy())

    # Calcular el loss de validación promedio en esta época
    val_loss = running_val_loss / len(dataloader_val)
    val_loss_list.append(val_loss)

    # Calcular el accuracy de validación
    val_accuracy = accuracy_score(all_val_labels, all_val_preds)

    # Calcular el accuracy de entrenamiento
    train_accuracy = accuracy_score(all_labels, all_preds)

    # Imprimir métricas de esta época
    print(f'Epoch {epoch} - Pérdida de entrenamiento: {train_loss:.4f} - Pérdida de validación: {val_loss:.4f} - Precisión del entrenamiento: {train_accuracy:.4f} - Precisión de la validación: {val_accuracy:.4f}')

    # Comprobar si el loss de validación está disminuyendo
    if val_loss < best_val_loss:
        best_val_loss = val_loss
        wait = 0
    else:
        wait += 1

    # Comprobar la condición de parada anticipada
    n_wait = 2
    if wait >= n_wait:
        print(f'Parada anticipada: No se ha observado mejora significativa en {n_wait} épocas.')
        print(f'Parada anticipada en la época {epoch}')
        break
end = time.time()
print('Finished Training, total time %f seconds' % (end - start))
# Imprimir los resultados finales
print(f'Precisión de entrenamiento al final del entrenamiento: {train_accuracy * 100:.2f}%')
print(f'Precisión de validación en la época {epoch}: {val_accuracy * 100:.2f}%')

import matplotlib.pyplot as plt

plt.figure(figsize=(12, 6))
plt.plot(train_loss_list, label='Training Loss', marker='o', markersize=5)
plt.plot(val_loss_list, label='Validation Loss', marker='o', markersize=5)
plt.grid(True)
plt.title('Escenario 2.d')
plt.xlabel('Epoch')
plt.ylabel('Pérdida')
plt.legend()
plt.show()

from sklearn.metrics import confusion_matrix
import seaborn as sns

# Calcular la matriz de confusión y el accuracy para el conjunto de validación
val_preds = np.array(all_val_preds)
val_labels = np.array(all_val_labels)
val_confusion = confusion_matrix(val_labels, val_preds, normalize='true')
val_accuracy_d = accuracy_score(val_labels, val_preds)

# Calcular la matriz de confusión y el accuracy para el conjunto de entrenamiento
train_preds = np.array(all_preds)
train_labels = np.array(all_labels)
train_confusion = confusion_matrix(train_labels, train_preds, normalize='true')
train_accuracy = accuracy_score(train_labels, train_preds)

# Crear una figura y ejes para la matriz de confusión
fig, axes = plt.subplots(1, 2, figsize=(15, 6))
fig.suptitle("Matrices de Confusión Normalizadas para escenario 2d", fontsize=16)

# Visualizar la matriz de confusión de validación
ax = axes[0]
sns.heatmap(val_confusion, annot=True, fmt='.2f', cmap='Blues', cbar=False, square=True, ax=ax, annot_kws={"size": 12})
ax.set_title("Validación")
ax.set_xlabel('Clase Predicha')
ax.set_ylabel('Clase Real')

# Visualizar la matriz de confusión de entrenamiento
ax = axes[1]
sns.heatmap(train_confusion, annot=True, fmt='.2f', cmap='Blues', cbar=False, square=True, ax=ax, annot_kws={"size": 12})
ax.set_title("Entrenamiento")
ax.set_xlabel('Clase Predicha')
ax.set_ylabel('Clase Real')

# Mostrar la figura
plt.show()

# Imprimir los resultados finales
print(f'Precisión de entrenamiento al final del entrenamiento: {train_accuracy * 100:.2f}%')
print(f'Precisión de validación en la época {epoch}: {val_accuracy_d * 100:.2f}%')

"""## Escenario 2e"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from sklearn.metrics import accuracy_score
import numpy as np

# Crear modelo para el escenario 2.e
model_e = nn.Sequential(
    nn.Linear(64, 10),  # Capa oculta 1 con 10 neuronas
    nn.ReLU(),  # Función de activación ReLU

    nn.Linear(10, 10),  # Capa oculta 2 con 10 neuronas
    nn.ReLU(),  # Función de activación ReLU

    nn.Linear(10, 10)  # Capa de salida con 10 neuronas (igual al número de clases)
)

device = torch.device('cuda')
model_e = model_e.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model_e.parameters(), lr=1e-3)
start = time.time()
# Inicializar variables para el seguimiento
max_epochs = 1000
best_val_loss = float('inf')
wait = 0  # Contador para la parada anticipada

train_loss_list = []
val_loss_list = []
all_train_preds = []
all_train_labels = []

for epoch in range(max_epochs):
    model_e.train()
    running_train_loss = 0.0
    all_preds = []
    all_labels = []

    for i, data in enumerate(dataloader_train, 0):
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)
        optimizer.zero_grad()
        outputs = model_e(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_train_loss += loss.item()
        all_preds.extend(outputs.argmax(dim=1).cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

    # Calcular el loss de entrenamiento promedio en esta época
    train_loss = running_train_loss / len(dataloader_train)
    train_loss_list.append(train_loss)

    model_e.eval()
    running_val_loss = 0.0
    all_val_preds = []
    all_val_labels = []

    with torch.no_grad():
        for data in dataloader_val:
            inputs = data["features"].to(device)
            labels = data["labels"].to(device)
            outputs = model_e(inputs)
            loss = criterion(outputs, labels)
            running_val_loss += loss.item()
            all_val_preds.extend(outputs.argmax(dim=1).cpu().numpy())
            all_val_labels.extend(labels.cpu().numpy())

    # Calcular el loss de validación promedio en esta época
    val_loss = running_val_loss / len(dataloader_val)
    val_loss_list.append(val_loss)

    # Calcular el accuracy de validación
    val_accuracy = accuracy_score(all_val_labels, all_val_preds)

    # Calcular el accuracy de entrenamiento
    train_accuracy = accuracy_score(all_labels, all_preds)

    # Imprimir métricas de esta época
    print(f'Epoch {epoch} - Pérdida de entrenamiento: {train_loss:.4f} - Pérdida de validación: {val_loss:.4f} - Precisión del entrenamiento: {train_accuracy:.4f} - Precisión de la validación: {val_accuracy:.4f}')

    # Comprobar si el loss de validación está disminuyendo
    if val_loss < best_val_loss:
        best_val_loss = val_loss
        wait = 0
    else:
        wait += 1

    # Comprobar la condición de parada anticipada
    n_wait = 10
    if wait >= n_wait:
        print(f'Parada anticipada: No se ha observado mejora significativa en {n_wait} épocas.')
        print(f'Parada anticipada en la época {epoch}')
        break
end = time.time()
print('Finished Training, total time %f seconds' % (end - start))
# Imprimir los resultados finales
print(f'Precisión de entrenamiento al final del entrenamiento: {train_accuracy * 100:.2f}%')
print(f'Precisión de validación en la época {epoch}: {val_accuracy * 100:.2f}%')

import matplotlib.pyplot as plt

plt.figure(figsize=(12, 6))
plt.plot(train_loss_list, label='Training Loss', marker='o', markersize=5)
plt.plot(val_loss_list, label='Validation Loss', marker='o', markersize=5)
plt.grid(True)
plt.title('Escenario 2.e')
plt.xlabel('Epoch')
plt.ylabel('Pérdida')
plt.legend()
plt.show()

from sklearn.metrics import confusion_matrix
import seaborn as sns

# Calcular la matriz de confusión y el accuracy para el conjunto de validación
val_preds = np.array(all_val_preds)
val_labels = np.array(all_val_labels)
val_confusion = confusion_matrix(val_labels, val_preds, normalize='true')
val_accuracy_e = accuracy_score(val_labels, val_preds)

# Calcular la matriz de confusión y el accuracy para el conjunto de entrenamiento
train_preds = np.array(all_preds)
train_labels = np.array(all_labels)
train_confusion = confusion_matrix(train_labels, train_preds, normalize='true')
train_accuracy = accuracy_score(train_labels, train_preds)

# Crear una figura y ejes para la matriz de confusión
fig, axes = plt.subplots(1, 2, figsize=(15, 6))
fig.suptitle("Matrices de Confusión Normalizadas para escenario 2e", fontsize=16)

# Visualizar la matriz de confusión de validación
ax = axes[0]
sns.heatmap(val_confusion, annot=True, fmt='.2f', cmap='Blues', cbar=False, square=True, ax=ax, annot_kws={"size": 12})
ax.set_title("Validación")
ax.set_xlabel('Clase Predicha')
ax.set_ylabel('Clase Real')

# Visualizar la matriz de confusión de entrenamiento
ax = axes[1]
sns.heatmap(train_confusion, annot=True, fmt='.2f', cmap='Blues', cbar=False, square=True, ax=ax, annot_kws={"size": 12})
ax.set_title("Entrenamiento")
ax.set_xlabel('Clase Predicha')
ax.set_ylabel('Clase Real')

# Mostrar la figura
plt.show()

# Imprimir los resultados finales
print(f'Precisión de entrenamiento al final del entrenamiento: {train_accuracy * 100:.2f}%')
print(f'Precisión de validación en la época {epoch}: {val_accuracy_e * 100:.2f}%')

"""##  Escenario 2f"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from sklearn.metrics import accuracy_score
import numpy as np

# Crear modelo para el escenario 2.f
model_f = nn.Sequential(
    nn.Linear(64, 40),  # Capa oculta 1 con 40 neuronas
    nn.ReLU(),          # Función de activación ReLU

    nn.Linear(40, 40),  # Capa oculta 2 con 40 neuronas
    nn.ReLU(),          # Función de activación ReLU

    nn.Linear(40, 10)   # Capa de salida con 10 neuronas (igual al número de clases)
)

device = torch.device('cuda')
model_f = model_f.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model_f.parameters(), lr=1e-3)
start = time.time()
# Inicializar variables para el seguimiento
max_epochs = 1000
best_val_loss = float('inf')
wait = 0  # Contador para la parada anticipada

train_loss_list = []
val_loss_list = []
all_train_preds = []
all_train_labels = []

for epoch in range(max_epochs):
    model_f.train()
    running_train_loss = 0.0
    all_preds = []
    all_labels = []

    for i, data in enumerate(dataloader_train, 0):
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)
        optimizer.zero_grad()
        outputs = model_f(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_train_loss += loss.item()
        all_preds.extend(outputs.argmax(dim=1).cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

    # Calcular el loss de entrenamiento promedio en esta época
    train_loss = running_train_loss / len(dataloader_train)
    train_loss_list.append(train_loss)

    model_f.eval()
    running_val_loss = 0.0
    all_val_preds = []
    all_val_labels = []

    with torch.no_grad():
        for data in dataloader_val:
            inputs = data["features"].to(device)
            labels = data["labels"].to(device)
            outputs = model_f(inputs)
            loss = criterion(outputs, labels)
            running_val_loss += loss.item()
            all_val_preds.extend(outputs.argmax(dim=1).cpu().numpy())
            all_val_labels.extend(labels.cpu().numpy())

    # Calcular el loss de validación promedio en esta época
    val_loss = running_val_loss / len(dataloader_val)
    val_loss_list.append(val_loss)

    # Calcular el accuracy de validación
    val_accuracy = accuracy_score(all_val_labels, all_val_preds)

    # Calcular el accuracy de entrenamiento
    train_accuracy = accuracy_score(all_labels, all_preds)

    # Imprimir métricas de esta época
    print(f'Epoch {epoch} - Pérdida de entrenamiento: {train_loss:.4f} - Pérdida de validación: {val_loss:.4f} - Precisión del entrenamiento: {train_accuracy:.4f} - Precisión de la validación: {val_accuracy:.4f}')

    # Comprobar si el loss de validación está disminuyendo
    if val_loss < best_val_loss:
        best_val_loss = val_loss
        wait = 0
    else:
        wait += 1

    # Comprobar la condición de parada anticipada
    n_wait = 2
    if wait >= n_wait:
        print(f'Parada anticipada: No se ha observado mejora significativa en {n_wait} épocas.')
        print(f'Parada anticipada en la época {epoch}')
        break
end = time.time()
print('Finished Training, total time %f seconds' % (end - start))
# Imprimir los resultados finales
print(f'Precisión de entrenamiento al final del entrenamiento: {train_accuracy * 100:.2f}%')
print(f'Precisión de validación en la época {epoch}: {val_accuracy * 100:.2f}%')

import matplotlib.pyplot as plt

plt.figure(figsize=(12, 6))
plt.plot(train_loss_list, label='Training Loss', marker='o', markersize=5)
plt.plot(val_loss_list, label='Validation Loss', marker='o', markersize=5)
plt.grid(True)
plt.title('Escenario 2.f')
plt.xlabel('Epoch')
plt.ylabel('Pérdida')
plt.legend()
plt.show()

from sklearn.metrics import confusion_matrix
import seaborn as sns

# Calcular la matriz de confusión y el accuracy para el conjunto de validación
val_preds = np.array(all_val_preds)
val_labels = np.array(all_val_labels)
val_confusion = confusion_matrix(val_labels, val_preds, normalize='true')
val_accuracy_f = accuracy_score(val_labels, val_preds)

# Calcular la matriz de confusión y el accuracy para el conjunto de entrenamiento
train_preds = np.array(all_preds)
train_labels = np.array(all_labels)
train_confusion = confusion_matrix(train_labels, train_preds, normalize='true')
train_accuracy = accuracy_score(train_labels, train_preds)

# Crear una figura y ejes para la matriz de confusión
fig, axes = plt.subplots(1, 2, figsize=(15, 6))
fig.suptitle("Matrices de Confusión Normalizadas para escenario 2f", fontsize=16)

# Visualizar la matriz de confusión de validación
ax = axes[0]
sns.heatmap(val_confusion, annot=True, fmt='.2f', cmap='Blues', cbar=False, square=True, ax=ax, annot_kws={"size": 12})  # Cambia el tamaño de fuente
ax.set_title("Validación")
ax.set_xlabel('Clase Predicha')
ax.set_ylabel('Clase Real')

# Visualizar la matriz de confusión de entrenamiento
ax = axes[1]
sns.heatmap(train_confusion, annot=True, fmt='.2f', cmap='Blues', cbar=False, square=True, ax=ax, annot_kws={"size": 12})  # Cambia el tamaño de fuente
ax.set_title("Entrenamiento")
ax.set_xlabel('Clase Predicha')
ax.set_ylabel('Clase Real')

# Mostrar la figura
plt.show()

# Imprimir los resultados finales
print(f'Precisión de entrenamiento al final del entrenamiento: {train_accuracy * 100:.2f}%')
print(f'Precisión de validación en la época {epoch}: {val_accuracy_f * 100:.2f}%')

"""## mejor accuracy para matriz de prueba"""

print(f'Precisión de validación para escenario 2a: {val_accuracy_a * 100:.2f}%')
print(f'Precisión de validación para escenario 2b: {val_accuracy_b * 100:.2f}%')
print(f'Precisión de validación para escenario 2c: {val_accuracy_c * 100:.2f}%')
print(f'Precisión de validación para escenario 2d: {val_accuracy_d * 100:.2f}%')
print(f'Precisión de validación para escenario 2e: {val_accuracy_e * 100:.2f}%')
print(f'Precisión de validación para escenario 2f: {val_accuracy_f * 100:.2f}%')

best_val_accuracy = 0.0  # Inicializa la mejor precisión en validación
best_scenario = None  # Inicializa el mejor escenario
# Define un diccionario que almacena los modelos correspondientes a cada escenario
scenario_models = {
    'escenario_a': model_a,
    'escenario_b': model_b,
    'escenario_c': model_c,
    'escenario_d': model_d,
    'escenario_e': model_e,
    'escenario_f': model_f,
}
# Almacena las métricas de precisión de validación para cada escenario
val_accuracy_dict = {
    'escenario_a': val_accuracy_a,
    'escenario_b': val_accuracy_b,
    'escenario_c': val_accuracy_c,
    'escenario_d': val_accuracy_d,
    'escenario_e': val_accuracy_e,
    'escenario_f': val_accuracy_f,
}

# Encuentra el escenario con la mejor precisión en validación
for scenario, val_accuracy in val_accuracy_dict.items():
    if val_accuracy > best_val_accuracy:
        best_val_accuracy = val_accuracy
        best_scenario = scenario



# Carga el modelo correspondiente al mejor escenario
best_test_model = scenario_models[best_scenario]

# Realiza las mismas operaciones para calcular la matriz de confusión en el conjunto de prueba
test_preds = []
test_labels = []

with torch.no_grad():
    for data in dataloader_test:
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)
        outputs = best_test_model(inputs)
        test_preds.extend(outputs.argmax(dim=1).cpu().numpy())
        test_labels.extend(labels.cpu().numpy())

# Calcula la matriz de confusión en el conjunto de prueba
test_confusion = confusion_matrix(test_labels, test_preds, normalize='true')
test_accuracy = accuracy_score(test_labels, test_preds)

# Crear una figura y ejes para la matriz de confusión
fig, ax = plt.subplots(figsize=(8, 6))
sns.heatmap(test_confusion, annot=True, fmt='.2f', cmap='Blues', cbar=False, square=True, ax=ax, annot_kws={"size": 12})
ax.set_title(f"Matriz de Confusión Normalizada en el Conjunto de Prueba - Escenario: {best_scenario}")
ax.set_xlabel('Clase Predicha')
ax.set_ylabel('Clase Real')

# Muestra la figura
plt.show()

# Imprime el resultado final
print(f"Mejor escenario: {best_scenario}")
print(f"Accuracy normalizado en el conjunto de prueba: {test_accuracy * 100:.2f}%")